---
title: "How are Phytophthora effectors taken into plant cells?"
author: "Marek Gierlinski"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme:
      bootswatch: journal
      primary: "#2fa4e7"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, autodep = TRUE, warning = FALSE)
okabe_ito_palette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "grey80", "grey30", "black")
```


```{r libraries, echo=FALSE}
suppressPackageStartupMessages({
  source("../packages.R") 
})
```

Collaborators: Paul Birch, Haixia Wang

#  {.tabset}

## Paired sets

### Load all data

Read all paired data from Excel files.

```{r read_data}
sets <- tribble(
  ~set, ~file,
  "hpNbAra6", "HaixiaWang",
  "hpCHC_ATTA", "Paired- hpCHC 04314 percentage",
  "hpCHC", "Paired- hpCHC ATTA",
  "hpNbPP1c", "Paired- hpNbPP1c ATTA"
) %>% 
  mutate(file = str_glue("../data/{file}_curated.xlsx"))

dat <- map2_dfr(sets$set, sets$file, function(set, file) {
  read_excel(file) %>%
    pivot_longer(-experiment, names_to = "condition") %>% 
    add_column(set = set, .before = 1) %>% 
    mutate(across(c(experiment, set), as_factor)) %>% 
    group_by(set, experiment, condition) %>%
    mutate(
      n_rep = n(),
      replicate = 1:n_rep
    ) %>% 
    ungroup() %>% 
    group_by(set) %>% 
    mutate(
      group = condition %>% 
        as_factor() %>%
        as.integer()
    ) %>% 
    ungroup() %>% 
    pivot_wider(id_cols = c(set, experiment, replicate, n_rep), names_from = group, values_from = c(condition, value)) %>% 
    mutate(dif = value_2 - value_1)
})
```

This is what our combined data look like (first 5 and last 5 rows):

```{r show_data}
bind_rows(head(dat, 5), tail(dat, 5)) %>% 
  flextable() %>% 
  hline(i = 5)
```

Make an overview plot. Lines join pairs, colours indicate increase or decrease upont treatment.

```{r overview_plot, fig.width=6, fig.height=4}
pl <- dat %>%
  arrange(set, experiment) %>% 
  group_split(set) %>% 
  map(function(d) {
    ggplot(d, aes(x = condition_1, xend = condition_2, y = value_1, yend = value_2)) +
      theme_bw() +
      theme(
        panel.grid = element_blank(),
        legend.position = "none"
      ) +
      geom_segment(aes(colour = as.factor(sign(dif))), alpha = 0.3) +
      geom_point() +
      geom_point(aes(x = condition_2, y = value_2)) +
      scale_colour_manual(values = c("#E69F00", "grey80", "#56B4E9")) +
      facet_wrap(~ experiment, ncol = 4) +
      labs(x = "Condition", y = "Value")
  }) %>% 
  set_names(levels(dat$set))
```

### hpNbAra6

```{r plot_hpNbAra6}
pl$hpNbAra6
```

### hpCHC_ATTA

```{r plot_hpCHC_ATTA}
pl$hpCHC_ATTA
```

### hpCHC

```{r plot_hpCHC}
pl$hpCHC
```

### hpNbPP1c

```{r plot_hpNbPP1c}
pl$hpNbPP1c
```

### Paried differences

Now we can look at differences for each pair between the two conditions in one combined plot.

PLOT MOVED DOWN TO INCLUDE SIGNIFICANCE DATA

### ANOVA

The pair difference data are set up in a convenient way to perform ANOVA analysis. We do ANOVA for each set separately. The null hypothesis is that the means from all experiments are equal. I used some advanced R here, but this is only a wrapper to do the test and tidy up data for all sets in one go. At the centre of this are just two R commands: `lm` to create a linear model and `anova` to perform ANOVA.

```{r anova}
dat %>%
  select(set, experiment, dif) %>%
  nest(data = c(experiment, dif)) %>%
  mutate(fit = map(data, ~ lm(dif ~ experiment, data = .x) %>% anova() %>% tidy())) %>%
  unnest(fit) %>%
  filter(term == "experiment") %>%
  select(set, df, sumsq, meansq, statistic, p.value) %>%
  mutate(across(where(is.numeric), ~ signif(.x, 2))) %>%
  flextable() %>%
  bg(i = ~ p.value < 0.05, bg = "wheat")
```

The last two sets have p-value < 0.05, which means we can reject the null hypothesis about equality of means - there are real differences between the experiments and we should not be using aggregated data. Note: this depends on how strict we are. If we use a 0.01 limit for p-value, then all data can be aggregated.

### t-test

We are going to perform a paired t-test for each set and experiment separately. This corresponds to a one-sample t-test of differences against zeroes.

First, define functions to make per experiment and aggregated tests, which can be used both with t-test and Wilcoxon test:

```{r fun_test}
per_exp_test <- function(d, FUN) {
  d %>%
    filter(n_rep > 2) %>%
    select(set, experiment, value_1, value_2, n_rep) %>%
    nest(data = c(value_1, value_2)) %>%
    mutate(fit = map(data, ~ FUN(.x$value_2, .x$value_1, paired = TRUE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    group_by(set) %>%
    mutate(p.adj = p.adjust(p.value, method = "BH")) %>%
    ungroup() %>%
    select(set, experiment, n_rep, mean_dif = estimate, conf.low, conf.high, stat = statistic, p.value, p.adj)
}

aggr_test <- function(d, FUN) {
  d %>%
    select(set, value_1, value_2) %>%
    nest(data = c(value_1, value_2)) %>%
    mutate(fit = map(data, ~ FUN(.x$value_2, .x$value_1, paired = TRUE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    select(set,  mean_dif = estimate, conf.low, conf.high, stat = statistic, p.value)
}
```

#### Per experiment

Paired t-test done on each experiment separately. I find Benjamini-Hochberg adjusted p-values within each set (we treat data sets as completely independent). Statistically significant results are highlighted.

```{r t_per_experiment}
test_result <- per_exp_test(dat, t.test) 
test_result %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.adj < 0.05, bg = "wheat", j = 2:9)
```


The plot below shows differences between the knock-out and control (grey points) the mean (horizontal lines) and 95% confidence intervals (vertical lines) for each experiment in each set. Where the 95% CI does not overlap with the null hypothesis line (zero - horizontal grey dotted line) the result is statistically significant at 0.05 level.

```{r dif_plot_plot, fig.width=7, fig.height=6}
dat_mean <- dat %>% 
  group_by(set, experiment) %>% 
  summarise(mean_dif = mean(dif))

g <- ggplot(dat) +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  geom_hline(yintercept = 0, colour = "grey70", linetype = "dotted") +
  geom_beeswarm(aes(x = experiment, y = dif), size = 1.6, cex = 1.6, colour = "grey60") +
  # use errorbar to create a horizontal bar
  geom_errorbar(data = dat_mean, aes(x = experiment, ymin = mean_dif, ymax = mean_dif),
                colour = "black", width = 0.4, size = 1.05) +
  geom_segment(data = test_result, aes(x = experiment, xend = experiment, y = conf.low, yend = conf.high),
               colour = "black", size = 1.05) +
  facet_wrap(~ set, scales = "free") +
  labs(x = "Experiment", y = "Difference")
g
ggsave("fig_1.pdf", g, device = "pdf", width = 6, height = 6)
```

#### Aggregated

Paired t-test done on aggregated experiments within each set.

```{r t_aggregated}
aggr_test(dat, t.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  set_formatter(p.value = \(x) sprintf("%2.1e", x))
```

As expected, using aggregated data improves power of the experiment and we have a significant result.

### Non-parametric test

If we are worried about data distribution, we can perform a non-parametric Mann-Whitney test (also known as Wilcoxon rank sum test).

#### Per experiment

```{r wilcox_per_experiment, warning=FALSE}
per_exp_test(dat, wilcox.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.adj < 0.05, bg = "wheat", j = 2:9)
```


#### Aggregated

```{r wilcox_aggregated, warning=FALSE}
aggr_test(dat, wilcox.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  set_formatter(
    p.value = \(x) sprintf("%2.1e", x),
    p.adj = \(x) sprintf("%2.1e", x)
  )
```




## Unpaired set

### Quick look at data

Read data from Excel files.

```{r read_data_unpaired}
dat_un <- read_excel("../data/non-Paired hpCHC 04314 intensity_curated.xlsx") %>%
    pivot_longer(-experiment, names_to = "condition") %>% 
    mutate(experiment = as_factor(experiment)) %>% 
    group_by(experiment, condition) %>% 
    mutate(n_rep = n(), replicate = 1:n_rep) %>% 
    ungroup() %>% 
    drop_na()
```

This is what our data look like (first and last 5 rows):

```{r show_data_unpaired}
bind_rows(head(dat_un, 5), tail(dat_un, 5)) %>% 
  flextable() %>% 
  hline(i = 5)
```

Make an overview plot:

```{r overview_plot_unpaired, fig.width=10, fig.height=4}
dat_un %>%
  ggplot(aes(x =  condition, y = value)) +
  theme_bw() +
  geom_quasirandom(width = 0.1) +
  facet_wrap(~ experiment, ncol = 7)
```

### Normality

We have enough data to look at normality in each experiment/condition. The Anderson-Darling test we use requires more than 7 replicates.

```{r normality_un}
dat_un %>%
  filter(n_rep > 7) %>% 
  select(experiment, condition, value) %>%
  nest(data = value) %>%
  mutate(fit = map(data, ~ ad.test(.x$value) %>% tidy())) %>%
  unnest(fit) %>%
  select(experiment, condition, stat = statistic, p.value) %>%
  mutate(across(c(stat, p.value), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.value < 0.05, bg = "wheat", j = 2:4)
```

Formally, three experiment/conditions are non-normal. However, we are going to do a t-test and a non-parametric test as well to confirm results.

### ANOVA

This is a two-way ANOVA, looking at the effects of experiment and condition.

```{r anova_unpaired}
fit <- lm(value ~ experiment + condition, data = dat_un)
anova(fit)
```

Both are significant, hence we should not be aggregating data.

### Statistical tests

Again, we define a helper function to perform a test.

```{r un_test_fun}
per_exp_test_un <- function(d, FUN) {
  d %>%
    select(experiment, condition, value) %>%
    nest(data = c(condition, value)) %>%
    mutate(fit = map(data, ~ FUN(value ~ condition, data = .x, paired = FALSE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    select(experiment, mean_dif = estimate, conf.low, conf.high, stat = statistic, p.value)
} 
```

#### t-test

t-test between the conditions performed for each experiment separately.

```{r t_per_exp_unparied}
per_exp_test_un(dat_un, t.test) %>% 
    mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.value < 0.05, bg = "wheat")
```

Only experiments 4 and 5 show a significant difference. This doesn't mean that there is no difference in other experiments - we simply don't have enough evidence.

### Non-parametric test

Mann-Whitney test.

```{r wilcox_per_exp_unparied}
per_exp_test_un(dat_un, wilcox.test) %>% 
    mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.value < 0.05, bg = "wheat")
```

