---
title: "How are Phytophthora effectors taken into plant cells?"
author: "Marek Gierlinski"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme:
      bootswatch: journal
      primary: "#2fa4e7"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, autodep = TRUE, warning = FALSE)
okabe_ito_palette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "grey80", "grey30", "black")
```


```{r libraries, echo=FALSE}
suppressPackageStartupMessages({
  source("../packages.R") 
})
```

Collaborators: Paul Birch, Haixia Wang

#  {.tabset}

## Paired sets

### Load all data

Read all paired data from Excel files.

```{r read_data}
sets <- tribble(
  ~set, ~file,
  "hpNbAra6", "HaixiaWang",
  "hpCHC_ATTA", "Paired- hpCHC 04314 percentage",
  "hpCHC", "Paired- hpCHC ATTA",
  "hpNbPP1c", "Paired- hpNbPP1c ATTA"
) %>% 
  mutate(file = str_glue("../data/{file}_curated.xlsx"))

dat <- map2_dfr(sets$set, sets$file, function(set, file) {
  read_excel(file) %>%
    pivot_longer(-experiment, names_to = "condition") %>% 
    add_column(set = set, .before = 1) %>% 
    mutate(across(c(experiment, set), as_factor)) %>% 
    group_by(set, experiment, condition) %>%
    mutate(
      n_rep = n(),
      replicate = 1:n_rep
    ) %>% 
    ungroup() %>% 
    group_by(set) %>% 
    mutate(
      group = condition %>% 
        as_factor() %>%
        as.integer()
    ) %>% 
    ungroup() %>% 
    pivot_wider(id_cols = c(set, experiment, replicate, n_rep), names_from = group, values_from = c(condition, value)) %>% 
    mutate(dif = value_2 - value_1)
})
```

This is what our combined data look like (first 5 and last 5 rows):

```{r show_data}
bind_rows(head(dat, 5), tail(dat, 5)) %>% 
  flextable() %>% 
  hline(i = 5)
```

Make an overview plot. Lines join pairs, colours indicate increase or decrease upont treatment.

```{r overview_plot, fig.width=6, fig.height=4}
pl <- dat %>%
  arrange(set, experiment) %>% 
  group_split(set) %>% 
  map(function(d) {
    ggplot(d, aes(x = condition_1, xend = condition_2, y = value_1, yend = value_2)) +
      theme_bw() +
      theme(
        panel.grid = element_blank(),
        legend.position = "none"
      ) +
      geom_segment(aes(colour = as.factor(sign(dif))), alpha = 0.3) +
      geom_point() +
      geom_point(aes(x = condition_2, y = value_2)) +
      scale_colour_manual(values = c("#E69F00", "grey80", "#56B4E9")) +
      facet_wrap(~ experiment, ncol = 4) +
      labs(x = "Condition", y = "Value")
  }) %>% 
  set_names(levels(dat$set))
```

### hpNbAra6

```{r plot_hpNbAra6}
pl$hpNbAra6
```

### hpCHC_ATTA

```{r plot_hpCHC_ATTA}
pl$hpCHC_ATTA
```

### hpCHC

```{r plot_hpCHC}
pl$hpCHC
```

### hpNbPP1c

```{r plot_hpNbPP1c}
pl$hpNbPP1c
```

### Paried differences

Now we can look at differences for each pair between the two conditions in one combined plot.

PLOT MOVED DOWN TO INCLUDE SIGNIFICANCE DATA

### ANOVA

The pair difference data are set up in a convenient way to perform ANOVA analysis. We do ANOVA for each set separately. The null hypothesis is that the means from all experiments are equal. I used some advanced R here, but this is only a wrapper to do the test and tidy up data for all sets in one go. At the centre of this are just two R commands: `lm` to create a linear model and `anova` to perform ANOVA.

```{r anova}
dat %>%
  select(set, experiment, dif) %>%
  nest(data = c(experiment, dif)) %>%
  mutate(fit = map(data, ~ lm(dif ~ experiment, data = .x) %>% anova() %>% tidy())) %>%
  unnest(fit) %>%
  filter(term == "experiment") %>%
  select(set, df, sumsq, meansq, statistic, p.value) %>%
  mutate(across(where(is.numeric), ~ signif(.x, 2))) %>%
  flextable() %>%
  bg(i = ~ p.value < 0.05, bg = "wheat")
```

The last two sets have p-value < 0.05, which means we can reject the null hypothesis about equality of means - there are real differences between the experiments and we should not be using aggregated data. Note: this depends on how strict we are. If we use a 0.01 limit for p-value, then all data can be aggregated.

### t-test

We are going to perform a paired t-test for each set and experiment separately. This corresponds to a one-sample t-test of differences against zeroes.

First, define functions to make per experiment and aggregated tests, which can be used both with t-test and Wilcoxon test:

```{r fun_test}
per_exp_test <- function(d, FUN) {
  d %>%
    filter(n_rep > 2) %>%
    select(set, experiment, value_1, value_2, n_rep) %>%
    nest(data = c(value_1, value_2)) %>%
    mutate(fit = map(data, ~ FUN(.x$value_2, .x$value_1, paired = TRUE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    group_by(set) %>%
    mutate(p.adj = p.adjust(p.value, method = "BH")) %>%
    ungroup() %>%
    select(set, experiment, n_rep, mean_dif = estimate, conf.low, conf.high, stat = statistic, p.value, p.adj)
}

aggr_test <- function(d, FUN) {
  d %>%
    select(set, value_1, value_2) %>%
    nest(data = c(value_1, value_2)) %>%
    mutate(fit = map(data, ~ FUN(.x$value_2, .x$value_1, paired = TRUE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    select(set,  mean_dif = estimate, conf.low, conf.high, stat = statistic, p.value)
}
```

#### Per experiment

Paired t-test done on each experiment separately. I find Benjamini-Hochberg adjusted p-values within each set (we treat data sets as completely independent). Statistically significant results are highlighted.

```{r t_per_experiment}
test_result <- per_exp_test(dat, t.test) 
test_result %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.adj < 0.05, bg = "wheat", j = 2:9)
```


The plot below shows differences between the knock-out and control (grey points) the mean (horizontal lines) and 95% confidence intervals (vertical lines) for each experiment in each set. Where the 95% CI does not overlap with the null hypothesis line (zero - horizontal grey dotted line) the result is statistically significant at 0.05 level.

```{r dif_plot_plot, fig.width=7, fig.height=6}
dat_mean <- dat %>% 
  group_by(set, experiment) %>% 
  summarise(mean_dif = mean(dif))

g <- ggplot(dat) +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  geom_hline(yintercept = 0, colour = "grey70", linetype = "dotted") +
  geom_beeswarm(aes(x = experiment, y = dif), size = 1.6, cex = 1.6, colour = "grey60") +
  # use errorbar to create a horizontal bar
  geom_errorbar(data = dat_mean, aes(x = experiment, ymin = mean_dif, ymax = mean_dif),
                colour = "black", width = 0.4, size = 1.05) +
  geom_segment(data = test_result, aes(x = experiment, xend = experiment, y = conf.low, yend = conf.high),
               colour = "black", size = 1.05) +
  facet_wrap(~ set, scales = "free") +
  labs(x = "Experiment", y = "Difference")
g
ggsave("fig_1.pdf", g, device = "pdf", width = 6, height = 6)
```

#### Aggregated

Paired t-test done on aggregated experiments within each set.

```{r t_aggregated}
aggr_test(dat, t.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  set_formatter(p.value = \(x) sprintf("%2.1e", x))
```

As expected, using aggregated data improves power of the experiment and we have a significant result.

### Non-parametric test

If we are worried about data distribution, we can perform a non-parametric Mann-Whitney test (also known as Wilcoxon rank sum test).

#### Per experiment

```{r wilcox_per_experiment, warning=FALSE}
per_exp_test(dat, wilcox.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.adj < 0.05, bg = "wheat", j = 2:9)
```


#### Aggregated

```{r wilcox_aggregated, warning=FALSE}
aggr_test(dat, wilcox.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  set_formatter(
    p.value = \(x) sprintf("%2.1e", x),
    p.adj = \(x) sprintf("%2.1e", x)
  )
```




## Unpaired set

### Quick look at data

Read data from Excel files.

```{r read_data_unpaired}
sets_un <- tribble(
  ~set, ~file,
  "hpCHC", "nonpaired hpCHC 04314",
  "NbAra6-GFP-P30", "nonpaired NbAra6-GFP P30",
  "NbAra6-GFP-P100", "nonpaired NbAra6-GFP P100",
  "NbCLC-GFP-P30", "nonpaired NbCLC-GFP P30",
  "NbCLC-GFP-P100", "nonpaired NbCLC-GFP P100"
) %>% 
  mutate(file = str_glue("../data/{file}.xlsx"))

dat_un <- map2_dfr(sets_un$set, sets_un$file, function(set, file) {
  read_excel(file) %>%
    pivot_longer(-experiment, names_to = "condition") %>% 
    mutate(experiment = as_factor(experiment)) %>% 
    group_by(experiment, condition) %>% 
    mutate(n_rep = n(), replicate = 1:n_rep) %>% 
    ungroup() %>% 
    drop_na() %>% 
    add_column(set = set, .before = 1)
}) %>% 
  mutate(set = as_factor(set))
```

This is what our data look like (first and last 5 rows):

```{r show_data_unpaired}
bind_rows(head(dat_un, 5), tail(dat_un, 5)) %>% 
  flextable() %>% 
  hline(i = 5) %>% 
  width(j = 1, width = 2)
```

Make an overview plots:

```{r overview_plot_unpaired, fig.width=10, fig.height=4}
pl <- dat_un %>%
  arrange(set, experiment) %>% 
  group_split(set) %>% 
  map(function(d) {
    ggplot(d, aes(x =  condition, y = value)) +
    theme_bw() +
    geom_quasirandom(width = 0.1) +
    facet_wrap(~ experiment, ncol = 7)
  }) %>% 
  set_names(levels(dat_un$set))
```

### hpCHC

```{r fig_un_hpCHC, fig.width=10, fig.height=4}
pl$hpCHC
```

### NbAra6-GFP-P30

```{r fig_un_NbAra6-GFP-P30, fig.width=4, fig.height=4}
pl$`NbAra6-GFP-P30`
```

### NbAra6-GFP-P100

```{r fig_un_NbAra6-GFP-P100, fig.width=4, fig.height=4}
pl$`NbAra6-GFP-P100`
```


### NbCLC-GFP-P30

```{r fig_un_NbCLC-GFP-P30, fig.width=4, fig.height=4}
pl$`NbCLC-GFP-P30`
```

### NbCLC-GFP-P100

```{r fig_un_NbCLC-GFP-P100, fig.width=4, fig.height=4}
pl$`NbCLC-GFP-P100`
```



### Normality

We have enough data to look at normality in each experiment/condition. The Anderson-Darling test we use requires more than 7 replicates.

```{r normality_un}
dat_un %>%
  filter(n_rep > 7) %>% 
  select(set, experiment, condition, value) %>%
  nest(data = value) %>%
  mutate(fit = map(data, ~ ad.test(.x$value) %>% tidy())) %>%
  unnest(fit) %>%
  select(set, experiment, condition, stat = statistic, p.value) %>%
  mutate(across(c(stat, p.value), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.value < 0.05, bg = "wheat", j = 2:4) %>% 
  width(j = 1, width = 2)
```

Formally, three experiment/conditions are non-normal. However, we are going to do a t-test and a non-parametric test as well to confirm results.

### ANOVA

This is a two-way ANOVA, looking at the effects of experiment and condition.

```{r anova_unpaired}
dat_un %>%
  select(set, experiment, condition, value) %>%
  nest(data = c(experiment, condition, value)) %>%
  mutate(fit = map(data, ~ lm(value ~ experiment + condition, data = .x) %>% anova() %>% tidy())) %>%
  unnest(fit) %>%
  filter(term != "Residuals") %>%
  select(set, term, df, sumsq, meansq, statistic, p.value) %>%
  mutate(across(where(is.numeric), ~ signif(.x, 3))) %>%
  flextable() %>%
  bg(i = ~ p.value < 0.05, bg = "wheat") %>% 
  width(j = 1, width = 2) %>% 
  set_formatter(
    p.value = \(x) sprintf("%2.1e", x)
  )
```

First two sets have significant "experiment" term, that is, we detect significant differences between experiments. These, perhaps, should not be aggregated.


### Statistical tests

Below, I perform all tests, both aggregated and per experiment for all data - as this is simpler to do in my code. I suggest that per experiment tests are more robust.


Again, we define a helper function to perform a test.

```{r un_test_fun}
per_exp_test_un <- function(d, FUN) {
  d %>%
    select(set, experiment, condition, value) %>%
    nest(data = c(condition, value)) %>%
    mutate(fit = map(data, ~ FUN(value ~ condition, data = .x, paired = FALSE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    group_by(set) %>%
    mutate(p.adj = p.adjust(p.value, method = "BH")) %>%
    ungroup() %>%
    select(set, experiment, estimate, conf.low, conf.high, stat = statistic, p.value, p.adj)
}

aggr_test_un <- function(d, FUN) {
  d %>%
    select(set, condition, value) %>%
    nest(data = c(condition, value)) %>%
    mutate(fit = map(data, ~ FUN(value ~ condition, data = .x, paired = FALSE, conf.int = TRUE) %>% tidy())) %>%
    unnest(fit) %>%
    select(set,  estimate, conf.low, conf.high, stat = statistic, p.value)
}
```

#### t-test

##### Per experiment

```{r t_per_exp_unparied}
un_t_test <- per_exp_test_un(dat_un, t.test)
un_t_test %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.adj < 0.05, bg = "wheat") %>% 
  width(j = 1, width = 2) %>% 
  set_formatter(
    p.value = \(x) sprintf("%2.1e", x),
    p.adj = \(x) sprintf("%2.1e", x)
  )
```

Last time I forgot to correct for multiple tests in hpCHC. If adjusted p-values are used, there are no significant differences at 0.05 FDR level.

We can visualise test results in this figure. It shows the difference between means in the two conditions and 95% confidence intervals.

```{r dif_plot_plot_un, fig.width=7, fig.height=6}
g <- ggplot(un_t_test) +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  geom_hline(yintercept = 0, colour = "grey70", linetype = "dotted") +
  geom_errorbar(aes(x = experiment, ymin = conf.low, ymax = conf.high),
                colour = "black", width = 0.4) +
  geom_point(aes(x = experiment, y = estimate)) +
  facet_wrap(~ set, scales = "free") +
  labs(x = "Experiment", y = "Difference between means (treatment - control)")
g
ggsave("fig_2.pdf", g, device = "pdf", width = 6, height = 6)
```


### Non-parametric test

##### Per experiment

```{r wilcox_per_exp_unparied}
per_exp_test_un(dat_un, wilcox.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(j = 1) %>% 
  bg(i = ~ p.adj < 0.05, bg = "wheat") %>% 
  width(j = 1, width = 2) %>% 
  set_formatter(
    p.value = \(x) sprintf("%2.1e", x),
    p.adj = \(x) sprintf("%2.1e", x)
  )
```


#### Aggregated

```{r wilcox_aggregated_un, warning=FALSE}
aggr_test_un(dat_un, wilcox.test) %>% 
  mutate(across(where(is.numeric), ~signif(.x, 3))) %>% 
  flextable() %>% 
  theme_box() %>% 
  width(j = 1, width = 2) %>% 
  set_formatter(
    p.value = \(x) sprintf("%2.1e", x),
    p.adj = \(x) sprintf("%2.1e", x)
  )
```


